{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '../../dataset/trainingSample/trainingSample/'\n",
    "images = []\n",
    "labels = []\n",
    "for label in os.listdir(dir):\n",
    "    for image in os.listdir(dir + label + '/'):\n",
    "        images.append(cv2.imread(dir + label + '/' + image, cv2.IMREAD_GRAYSCALE) / 255.)\n",
    "        labels.append(int(label))\n",
    "images = np.array(images)\n",
    "images = images.reshape(images.shape[0], images.shape[1], images.shape[2], 1)\n",
    "labels = np.array(labels)\n",
    "labels = labels.reshape(labels.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(images[0].reshape(28, 28), cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(images[100].reshape(28, 28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_image = Input(shape=(28, 28, 1))\n",
    "    \n",
    "    x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_image)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(10)(x)\n",
    "    \n",
    "    model = Model(input_image, x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 3,194\n",
      "Trainable params: 3,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x229f2f0ea20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=1000, \n",
    "          validation_data=(X_test, y_test), \n",
    "          batch_size=16,\n",
    "          shuffle=True,\n",
    "          verbose=0,\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功: 處理程序 \"tensorboard.exe\" (PID 2512) 已經終止了。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!taskkill /im tensorboard.exe /f\n",
    "!del /q %TMP%\\.tensorboard-info\\*\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs --host 127.0.0.1 --port 6066"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 1.3816 - accuracy: 0.8833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3816100358963013, 0.8833333253860474]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -17.019903 -159.3101    -59.93164   -60.580505 -111.14244   -55.706707\n",
      "   -71.02482   -89.165474  -72.828606  -57.711723]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(images[0].reshape(1, 28, 28, 1)))\n",
    "print(np.argmax(model.predict(images[0].reshape(1, 28, 28, 1)), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\vkmouse\\tensorflow_2.2\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: save_model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'save_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('save_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 3,194\n",
      "Trainable params: 3,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(new_model.predict(images[0].reshape(1, 28, 28, 1)), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -17.019903, -159.3101  ,  -59.93164 ,  -60.580505, -111.14244 ,\n",
       "         -55.706707,  -71.02482 ,  -89.165474,  -72.828606,  -57.711723]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(images[0].reshape(1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Frezon model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Keras model to ConcreteFunction\n",
    "full_model = tf.function(lambda x: new_model(x))\n",
    "full_model = full_model.get_concrete_function(\n",
    "    x=tf.TensorSpec(new_model.inputs[0].shape, new_model.inputs[0].dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get frozen ConcreteFunction\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "frozen_func = convert_variables_to_constants_v2(full_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Frozen model layers: \n",
      "x\n",
      "model/conv2d/Conv2D/ReadVariableOp/resource\n",
      "model/conv2d/Conv2D/ReadVariableOp\n",
      "model/conv2d/Conv2D\n",
      "model/conv2d/BiasAdd/ReadVariableOp/resource\n",
      "model/conv2d/BiasAdd/ReadVariableOp\n",
      "model/conv2d/BiasAdd\n",
      "model/conv2d/Relu\n",
      "model/max_pooling2d/MaxPool\n",
      "model/conv2d_1/Conv2D/ReadVariableOp/resource\n",
      "model/conv2d_1/Conv2D/ReadVariableOp\n",
      "model/conv2d_1/Conv2D\n",
      "model/conv2d_1/BiasAdd/ReadVariableOp/resource\n",
      "model/conv2d_1/BiasAdd/ReadVariableOp\n",
      "model/conv2d_1/BiasAdd\n",
      "model/conv2d_1/Relu\n",
      "model/max_pooling2d_1/MaxPool\n",
      "model/conv2d_2/Conv2D/ReadVariableOp/resource\n",
      "model/conv2d_2/Conv2D/ReadVariableOp\n",
      "model/conv2d_2/Conv2D\n",
      "model/conv2d_2/BiasAdd/ReadVariableOp/resource\n",
      "model/conv2d_2/BiasAdd/ReadVariableOp\n",
      "model/conv2d_2/BiasAdd\n",
      "model/conv2d_2/Relu\n",
      "model/max_pooling2d_2/MaxPool\n",
      "model/flatten/Const\n",
      "model/flatten/Reshape\n",
      "model/dense/MatMul/ReadVariableOp/resource\n",
      "model/dense/MatMul/ReadVariableOp\n",
      "model/dense/MatMul\n",
      "model/dense/BiasAdd/ReadVariableOp/resource\n",
      "model/dense/BiasAdd/ReadVariableOp\n",
      "model/dense/BiasAdd\n",
      "Identity\n"
     ]
    }
   ],
   "source": [
    "layers = [op.name for op in frozen_func.graph.get_operations()]\n",
    "print(\"-\" * 50)\n",
    "print(\"Frozen model layers: \")\n",
    "for layer in layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Frozen model inputs: \n",
      "[<tf.Tensor 'x:0' shape=(None, 28, 28, 1) dtype=float32>]\n",
      "Frozen model outputs: \n",
      "[<tf.Tensor 'Identity:0' shape=(None, 10) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 50)\n",
    "print(\"Frozen model inputs: \")\n",
    "print(frozen_func.inputs)\n",
    "print(\"Frozen model outputs: \")\n",
    "print(frozen_func.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./frozen_models\\\\simple_frozen_graph.pb'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save frozen graph from frozen ConcreteFunction to hard drive\n",
    "tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "                  logdir=\"./frozen_models\",\n",
    "                  name=\"simple_frozen_graph.pb\",\n",
    "                  as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
